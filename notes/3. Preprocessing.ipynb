{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google's BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model imports\n",
    "cuda = torch.device('cuda')\n",
    "bert = BertModel.from_pretrained('bert-base-uncased').to(cuda)\n",
    "bert.eval()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = pickle.load(open('../data/infos.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'collection': 10194,\n",
       " 'genres': [16, 35, 10751],\n",
       " 'original_language': 'en',\n",
       " 'overview': \"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\",\n",
       " 'popularity': 25.398,\n",
       " 'production_companies': [3],\n",
       " 'production_countries': ['us'],\n",
       " 'release_year': 1995,\n",
       " 'release_month': 10,\n",
       " 'revenue': 373554033,\n",
       " 'runtime': 81,\n",
       " 'spoken_languages': ['en'],\n",
       " 'tagline': '',\n",
       " 'title': 'Toy Story',\n",
       " 'vote_average': 7.9,\n",
       " 'vote_count': 9787}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9db1f812ca9442285d288ada7fdd136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27278), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infos_tensor = {}\n",
    "for k,v in tqdm(infos.items()):\n",
    "    v = (v['overview'] + v['tagline'] + v['title'])[:512]\n",
    "    v = tokenizer.tokenize(v)\n",
    "    v = tokenizer.convert_tokens_to_ids(v)\n",
    "    v = torch.tensor(v).to(cuda)\n",
    "    infos_tensor[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "infos_sorted = OrderedDict(sorted(infos_tensor.items(), key=lambda t: t[1].size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301c3fce28624212ad5676fddbd94065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27278), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infos_bert = {}\n",
    "batch = []\n",
    "indexes = []\n",
    "max_size = 0\n",
    "batch_size = 10\n",
    "\n",
    "for i in tqdm(range(len(infos_sorted))):\n",
    "    idx, tensor = infos_sorted.popitem()\n",
    "    batch.append(tensor)\n",
    "    indexes.append(idx)\n",
    "    \n",
    "    if len(batch) >= batch_size:\n",
    "        seq_lengths = torch.tensor([len(seq) for seq in batch]).long().cuda()\n",
    "        seq_tensor = torch.zeros((len(batch), seq_lengths.max())).long().cuda()\n",
    "        \n",
    "        for idx, (seq, seqlen) in enumerate(zip(batch, seq_lengths)):\n",
    "            seq_tensor[idx, :seqlen] = torch.tensor(seq).long().cuda()\n",
    "            \n",
    "        _, output = bert(seq_tensor)\n",
    "\n",
    "        output = output.detach().cpu()\n",
    "        for i in range(output.size(0)):\n",
    "            infos_bert[indexes[i]] = output[i]\n",
    "            \n",
    "        batch = []\n",
    "        indexes = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dict([(i[0], i[1].numpy()) for i in infos_bert.items()]),\n",
    "            open('../data/texts_bert.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pytorch_pretrained_bert import GPT2Tokenizer, GPT2Model\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')\n",
    "gpt2 = GPT2Model.from_pretrained('gpt2').to(cuda)\n",
    "gpt2.eval()\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = pickle.load(open('../data/infos.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd388d0f9dc43f5b16badbc33878d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27278), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infos_tensor = {}\n",
    "for k,v in tqdm(infos.items()):\n",
    "    v = (v['overview'] + v['tagline'] + v['title'])[:512]\n",
    "    v = tokenizer.encode(v)\n",
    "    v = torch.tensor(v).to(cuda)\n",
    "    infos_tensor[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "infos_sorted = OrderedDict(sorted(infos_tensor.items(), key=lambda t: t[1].size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216a396b4e0744668948c5a5da78d741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27278), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infos_gpt2 = {}\n",
    "batch = []\n",
    "indexes = []\n",
    "max_size = 0\n",
    "batch_size = 5\n",
    "\n",
    "for i in tqdm(range(len(infos_sorted))):\n",
    "    idx, tensor = infos_sorted.popitem()\n",
    "    batch.append(tensor)\n",
    "    indexes.append(idx)\n",
    "    \n",
    "    if len(batch) >= batch_size:\n",
    "        seq_lengths = torch.tensor([len(seq) for seq in batch]).long().cuda()\n",
    "        seq_tensor = torch.zeros((len(batch), seq_lengths.max())).long().cuda()\n",
    "        \n",
    "        for idx, (seq, seqlen) in enumerate(zip(batch, seq_lengths)):\n",
    "            seq_tensor[idx, :seqlen] = torch.tensor(seq).long().cuda()\n",
    "            \n",
    "        output, _ = gpt2(seq_tensor)\n",
    "        output = output[:,-1]\n",
    "        output = output.detach().cpu()\n",
    "        for i in range(output.size(0)):\n",
    "            infos_gpt2[indexes[i]] = output[i]\n",
    "            \n",
    "        batch = []\n",
    "        indexes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dict([(i[0], i[1].numpy()) for i in infos_gpt2.items()]),\n",
    "            open('../data/texts_gpt2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
